{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "14696687",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (493932489.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [255]\u001b[0;36m\u001b[0m\n\u001b[0;31m    Lhea Beumer\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Lhea Beumer\n",
    "S4105427\n",
    "\n",
    "My model integrates the model I made for the previous assignment with a model that includes distraction \n",
    "and motivation. It is build on the assumptions that the length of a foreperiod of a previous trial in combination with the length of the foreperiod in the current trial\n",
    "influences response times. \n",
    "For every trial there is a chunk stored that holds both the time of the current fp and the pulses of this current \n",
    "fp (which represents the internal clock). Every trial, with exception of the first trial for each subject, a chunk\n",
    "with the highest activation level is retrieved. From this chunk, the pulses of the time belonging to that fp will be \n",
    "transferred back to time, representing the subjects estimate of the current fp in this trial. \n",
    "If this estimate (taken from a previous fp) is bigger than the current fp, the subject is prepared and 0.05 s \n",
    "will be taken from the max response time of 0.41 s. \n",
    "If this estimate (taken from a previous fp) is smaller than the current fp, the subject is unprepared and there\n",
    "will be a max response time of 0.41 s. \n",
    "If this estimate (taken from a previous fp) is bigger than the current fp, is in between the time of \n",
    "current foreperiod - 50 ms and the estimate for the next foreperiod, the response time has to be calculated by \n",
    "taking the max response time and withdrawing the current foreperiod - their estimate\n",
    "After every trial, a new chunk will be made that holds the information about the fp in the current trial, so\n",
    "that it could be retrieved to make an estimate at a later moment again. In other words, every trial a new\n",
    "chunk will be made.  \n",
    "The model uses constants for each condition target visibility that are withdrawn from the maximum  \n",
    "RT, derived from the data. Moreover, I modeled a goal competition between distraction and task goal in that resemble\n",
    "reward.\n",
    "I wrote the code that calculates the RTs per trial in a separate cel, so that this can be looped every trial\n",
    "in the full experiment, the code for which is written in the cel above that. I also included the code I ran\n",
    "in R studio to visualize the model estimates and the linear mixed-effectmodel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30793f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dmchunk import Chunk\n",
    "from model import Model\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8045de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(s):\n",
    "    rand = random.uniform(0.001,0.999)\n",
    "    return s * math.log((1 - rand)/rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c22e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pulses_to_time(pulses, t_0 = 0.011, a = 1.1, b = 0.015, add_noise = True):\n",
    "    \n",
    "    time = 0\n",
    "    pulse_duration = t_0\n",
    "    \n",
    "    while pulses > 0:\n",
    "        time = time + pulse_duration\n",
    "        pulses = pulses - 1\n",
    "        pulse_duration = a * pulse_duration + add_noise * noise(b * a * pulse_duration)\n",
    "    \n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ee00f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_pulses(time, t_0 = 0.011, a = 1.1, b = 0.015, add_noise = True):\n",
    "    \n",
    "    pulses = 0\n",
    "    pulse_duration = t_0\n",
    "    \n",
    "    while time >= pulse_duration:\n",
    "        time = time - pulse_duration\n",
    "        pulses = pulses + 1\n",
    "        pulse_duration = a * pulse_duration + add_noise * noise(b * a * pulse_duration)\n",
    "        \n",
    "    return pulses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6cbe4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t (s) \t pulses\n",
      "0 \t 0\n",
      "0.011 \t 1\n",
      "0.025 \t 2\n",
      "0.1 \t 6\n",
      "0.5 \t 18\n",
      "1 \t 24\n",
      "10 \t 46\n"
     ]
    }
   ],
   "source": [
    "intervals = [0, 0.011, 0.025, 0.1, 0.5, 1, 10]\n",
    "print(\"t (s)\", \"\\t\", \"pulses\")\n",
    "for t in intervals:\n",
    "    print(t, \"\\t\", time_to_pulses(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "7e2d5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithMotivation(Model):\n",
    "    \n",
    "    #constants tweaked for best model fit   \n",
    "    da = .7  # distraction activation\n",
    "    discount = .45 # discount due to motivation drop\n",
    "    \n",
    "    #if no reward\n",
    "    def discount_goal_activation(self):\n",
    "        self.ga -= self.discount\n",
    "       \n",
    "    #if reward \n",
    "    def add_goal_activation(self):\n",
    "        self.ga += self.discount\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"\\n=== Model ===\\n\" \\\n",
    "        \"Time: \" + str(self.time) + \" s \\n\" \\\n",
    "        \"Goal:\" + str(self.goal) + \"\\n\" \\\n",
    "        \"DM:\" + \"\\n\".join([str(c) for c in self.dm]) + \"\\n\" \\\n",
    "        \"ga: \" + str(self.ga) + \"\\n\" \n",
    "    \n",
    "    def distraction(self):\n",
    "        return self.da + self.noise(self.s) > self.ga + self.noise(self.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "978670d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACT-R defaults:\n",
    "\n",
    "#create a list of foreperiods\n",
    "periods=[.3, .6, 9]\n",
    "\n",
    "#min response time of 280 ms, taken from data\n",
    "min_response = 0.280 \n",
    "\n",
    "#50 ms added to RT if not prepared\n",
    "prepared = 0.05\n",
    "\n",
    "#add to RT if visibility is low\n",
    "visib = .02\n",
    "\n",
    "#activation noise\n",
    "activation_noise = 0.1\n",
    "\n",
    "# Experiment timing:\n",
    "\n",
    "inter_trial_interval = random.uniform(.5, .8)\n",
    "distraction_mean_time = 0.08 # average distraction time\n",
    "distraction_variation = 0.05 # variation in distraction (uniform)\n",
    "focus_loss_probability = 0.2 # probability to lose focus once prepared\n",
    "focus_latency = 0.2 # if we decide to stay focused, we focus for this amount of time\n",
    "\n",
    "def distraction_time():\n",
    "    return random.uniform(distraction_mean_time-distraction_variation,distraction_mean_time+distraction_variation)\n",
    "\n",
    "def init_model():\n",
    "    #use the model with motivation\n",
    "    m = ModelWithMotivation()\n",
    "    ch1 = Chunk(name = \"sr1\", slots = {\"isa\":\"foreperiod\"})\n",
    "    ch2 = Chunk(name = \"sr2\", slots = {\"isa\":\"foreperiod\"})\n",
    "    m.add_encounter(ch1)\n",
    "    m.add_encounter(ch2)\n",
    "    m.rt = -2.0\n",
    "    m.lf = 0.5\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "58755e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "#code for running the whole experiment with 10 subjects or it takes too long\n",
    "def experiment(subs=10):\n",
    "    \n",
    "    #make dataframe containing the variables for plotting\n",
    "    results = pd.DataFrame(columns = ['foreperiod', 'sub', 'RT', 'target_visibility', 'reward'])\n",
    "    \n",
    "    #loop experiment for all subjects\n",
    "    for sub in range(subs):\n",
    "        \n",
    "        #30 trials per block\n",
    "        trials= 10\n",
    "        \n",
    "        #16 blocks\n",
    "        blocks = 4\n",
    "        \n",
    "        #create a balanced nr of FPs per block resulting in 30 trials per block\n",
    "        Trials = [.3,.6,.9] * trials \n",
    "        \n",
    "        #create lists with possible reward and visibility situations\n",
    "        reward = [\"yes\", \"no\"]\n",
    "        visibility = [\"hi\",\"lo\"]\n",
    "        \n",
    "        #per block create a combination of reward and visibility resulting in 16 blocks\n",
    "        Blocks = list(itertools.product(reward, visibility)) * blocks\n",
    "        \n",
    "        #randomize combinations\n",
    "        random.shuffle(Blocks)\n",
    "        \n",
    "        #initialize model\n",
    "        m = init_model()\n",
    "        \n",
    "        m.s = activation_noise\n",
    "        \n",
    "        #start at trial 0\n",
    "        trialNum = 0\n",
    "        \n",
    "        goal_activation = False\n",
    "        \n",
    "        for block in Blocks:\n",
    "            \n",
    "            #randomize foreperiods\n",
    "            random.shuffle(Trials)\n",
    "            \n",
    "            #loop every block\n",
    "            reward, target_visibility = block\n",
    "            \n",
    "            if reward == \"no\" and goal_activation == False:\n",
    "                m.discount_goal_activation()\n",
    "                goal_activation = True\n",
    "                \n",
    "            elif reward ==\"yes\" and goal_activation == True:\n",
    "                m.add_goal_activation()\n",
    "                goal_activation = False\n",
    "            \n",
    "            #loop every trial\n",
    "            for foreperiod in Trials:\n",
    "\n",
    "                #calculate the RTs per trial \n",
    "                RT = run_one_trial(m, trialNum, foreperiod, target_visibility, reward)\n",
    "                          \n",
    "                #increase trial\n",
    "                trialNum += 1\n",
    "                \n",
    "                #append variables of interest to dataframe\n",
    "                results.loc[len(results)] = [foreperiod, sub, RT, target_visibility, reward]\n",
    "                \n",
    "        #make a csv file\n",
    "        results.to_csv('/Users/lheabeumer/Desktop/Results_model3_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "739c9834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_trial(m, trialNum, foreperiod, target_visibility, reward):\n",
    "    start_time = m.time \n",
    "    done = False\n",
    "    g = Chunk(name = \"goal\", slots = {\"isa\":\"goal\"})\n",
    "    m.goal = g\n",
    "    while not done:\n",
    "\n",
    "        if m.time - start_time < foreperiod and not m.distraction(): \n",
    "            \n",
    "                # stimulus is not there yet and we are not distracted, so we prepare\n",
    "                if not \"expectation\" in m.goal.slots:\n",
    "                    retrieval = Chunk(name = \"new_estimate_pulse\", slots = {\"isa\": \"foreperiod\"})\n",
    "                    m.time += 0.05\n",
    "                    chunk, latency = m.retrieve(retrieval)\n",
    "                    m.time += latency\n",
    "                    \n",
    "                    #try to fill the goal slot if a previous pulse guess exists\n",
    "                    try:\n",
    "                        m.goal.slots[\"expectation\"] = pulses_to_time(chunk.slots[\"previous pulse guess\"])\n",
    "                        \n",
    "                    #if it doesn't exist, set a high number so there will be a maximum response time\n",
    "                    except:\n",
    "                        m.goal.slots[\"expectation\"] = 2\n",
    "                        \n",
    "                #stimulus is not there and we are focused so increase time by focus latency       \n",
    "                else:\n",
    "                    m.time += focus_latency \n",
    "                    \n",
    "        elif m.time - start_time < foreperiod: #distracted\n",
    "            # do other things while waiting for the stimulus\n",
    "            m.time = m.time + distraction_time()\n",
    "            \n",
    "            # There is also a probability that we lose focus    \n",
    "            if \"expectation\" in m.goal.slots and random.uniform(0.0,1.0) < focus_loss_probability:\n",
    "                m.goal.slots[\"expectation\"] = 2\n",
    "                \n",
    "        # the stimulus has appeared\n",
    "        else:\n",
    "            \n",
    "            # we have a prediction\n",
    "            if \"expectation\" in m.goal.slots:\n",
    "                \n",
    "                if target_visibility == \"lo\":\n",
    "                    response_variable = min_response + visib \n",
    "                    \n",
    "                if target_visibility == \"hi\":\n",
    "                    response_variable = min_response    \n",
    "                    \n",
    "                #if we were not prepared\n",
    "                if m.goal.slots[\"expectation\"] > foreperiod:\n",
    "                    RT = response_variable + prepared\n",
    "\n",
    "                #if we were prepared\n",
    "                elif m.goal.slots[\"expectation\"] < foreperiod - prepared:\n",
    "                    RT = response_variable \n",
    "\n",
    "                #we were still preparing\n",
    "                if m.goal.slots[\"expectation\"] > foreperiod - prepared and m.goal.slots[\"expectation\"] < foreperiod:\n",
    "                    RT = response_variable + (foreperiod - m.goal.slots[\"expectation\"])\n",
    "                    \n",
    "            # we don't have a prediction (we got distracted)\n",
    "            else:\n",
    "                RT = min_response + prepared + distraction_time()\n",
    "    \n",
    "            #make a new chunk for each new foreperiod estimate\n",
    "            retrieval = Chunk(name = \"new_estimate_pulse\"+str([trialNum]), slots = {\"isa\": \"foreperiod\", \n",
    "                                                            \"previous pulse guess\": time_to_pulses(foreperiod)})\n",
    "            #store every new chunk in memory\n",
    "            m.add_encounter(retrieval)\n",
    "            \n",
    "            #increase time by the current foreperiod and trial interval\n",
    "            m.time += foreperiod + inter_trial_interval\n",
    "            \n",
    "            #trial is done\n",
    "            done = True\n",
    "       \n",
    "    #return RT to use in the full experiment\n",
    "    return RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a47c57f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f211e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#R code used for analysis\n",
    "\n",
    "#read data\n",
    "model_CM <- read.csv('Results_model3_1.csv.csv')\n",
    "\n",
    "#change names of columns so I can use the same code that was provided\n",
    "colnames(model_CM)[2]  <- \"fp\"\n",
    "colnames(model_CM)[3]  <- \"sub_id\"\n",
    "colnames(model_CM)[4]  <- \"response_time\"\n",
    "\n",
    "#delete a randomly attached column X from the dataframe \n",
    "model_CM <- subset(model_CM, select=-X)\n",
    "\n",
    "#take ms instead of sec, like the data\n",
    "model_CM$response_time <- 1000 * (model_CM$response_time)\n",
    "\n",
    "#the code that was provided to computed averages\n",
    "gave2 <- model_CM  %>% \n",
    "\tgroup_by(sub_id, fp, reward, target_visibility)  %>%        # Compute average RT per pp, per condition:\n",
    "\tsummarize(RT = mean(response_time))%>% \n",
    "\tplottab(gv=c('fp','reward','target_visibility'),\n",
    "            dv='RT', group='sub_id')                            # compute grand avg. w/ plottab()\n",
    "head(gave2)\n",
    "\n",
    "#bind the dataframes of the actual data and my model data\n",
    "all.se <- bind_rows(gave2, gave, .id=\"model\")\n",
    "\n",
    "#plot \n",
    "ggplot(all.se, aes(x=fp, y=RT, linetype=reward,shape=reward, color=model)) +     # ...and plot\n",
    "\tgeom_errorbar(aes(ymin=lower,ymax=upper), color='black',size=.5, width=.01) + \n",
    "\tgeom_line(size=.5) + \n",
    "\tgeom_point(size=3) + \n",
    "\tfacet_grid(.~target_visibility, labeller='label_both') + \n",
    "\ttheme_bw(base_size=20) + \n",
    "  scale_color_manual(labels = c(\"model\", \"data\"), values = c(\"red\", \"blue\")) +\n",
    "  theme_bw() +\n",
    "\tylim(275, 410) -> plot_II\n",
    "\n",
    "fig(10,7)\n",
    "plot_II\n",
    "\n",
    "#linear model\n",
    "m <- lmer(1/response_time ~ fp*reward*target_visibility + (1+fp|sub_id), data=model_CM)\n",
    "summary(m)\n",
    "anova(m)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
